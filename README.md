The aim of this project is to explore the effectiveness and optimization of XGBoost compared to the traditional Gradient Boosted Decision Tree (GBDT) model in classification problems.

In this project we will perform the following parts in sequence: acquiring data and data preprocessing, training the model, and evaluating the model. By using both GBDT and XGBoost models on the same dataset, this project attempts to carefully compare and analyze the performance metrics such as accuracy, precision, recall, and F1 scores in order to highlight the advantages of XGBoost in handling the classification task.

Through the comparative analysis, we aim to provide a comprehensive overview of how XGBoost improves upon the GBDT framework to gain insights into its applicability and superiority in solving classification challenges.
